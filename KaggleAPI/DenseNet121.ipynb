{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUERblhpvQvI",
        "outputId": "9cf381bf-5031-4723-9b2d-ca9b2d4ddebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/labeled-optical-coherence-tomography-oct\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"anirudhcv/labeled-optical-coherence-tomography-oct\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdiPMskT4xhx",
        "outputId": "160fbbd8-7f89-4010-af49-a3029f02c1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to downloaded dataset files: /kaggle/input/labeled-optical-coherence-tomography-oct\n",
            "\n",
            "'train' klasöründeki içerikler:\n",
            "  DRUSEN: 6206 görsel\n",
            "  CNV: 26218 görsel\n",
            "  NORMAL: 35973 görsel\n",
            "  DME: 8118 görsel\n",
            "\n",
            "'val' klasöründeki içerikler:\n",
            "  DRUSEN: 1773 görsel\n",
            "  CNV: 7491 görsel\n",
            "  NORMAL: 10278 görsel\n",
            "  DME: 2319 görsel\n",
            "\n",
            "'test' klasöründeki içerikler:\n",
            "  DRUSEN: 887 görsel\n",
            "  CNV: 3746 görsel\n",
            "  NORMAL: 5139 görsel\n",
            "  DME: 1161 görsel\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "downloaded_path = kagglehub.dataset_download(\"anirudhcv/labeled-optical-coherence-tomography-oct\")\n",
        "\n",
        "print(\"Path to downloaded dataset files:\", downloaded_path)\n",
        "\n",
        "# Veri seti yolu: kagglehub tarafından indirilen path'i kullan\n",
        "# İndirilen path'in içindeki 'Dataset - train+val+test' klasörüne işaret etmesi gerekiyor.\n",
        "dataset_path = os.path.join(downloaded_path, \"Dataset - train+val+test\")\n",
        "\n",
        "# Sınıf sayımlarını hesaplayan fonksiyon\n",
        "def count_images_in_folder(folder_path):\n",
        "    \"\"\"Verilen klasördeki sınıfların görsel sayılarını hesaplar.\"\"\"\n",
        "    class_counts = {}\n",
        "    # Check if the folder_path exists before listing\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Hata: Klasör bulunamadı: {folder_path}\")\n",
        "        return class_counts # Return empty if folder doesn't exist\n",
        "\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if os.path.isdir(class_folder):\n",
        "            num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
        "            class_counts[class_name] = num_images\n",
        "    return class_counts\n",
        "\n",
        "# Klasörleri tara ve sınıf sayılarını yazdır\n",
        "for folder in ['train', 'val', 'test']:\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    print(f\"\\n'{folder}' klasöründeki içerikler:\")\n",
        "\n",
        "    class_counts = count_images_in_folder(folder_path)\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"  {class_name}: {count} görsel\")"
      ]
    },
    {
      "source": [
        "# === Veri yolu ===\n",
        "# dataset_path = \"/kaggle/input/labeled-optical-coherence-tomography-oct/Dataset - train+val+test\" # Remove this hardcoded path\n",
        "\n",
        "# Use the path obtained from kagglehub.dataset_download\n",
        "# downloaded_path is defined in the previous cell\n",
        "dataset_path = os.path.join(downloaded_path, \"Dataset - train+val+test\")\n",
        "\n",
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# === Dataset yükle ===\n",
        "def load_datasets():\n",
        "    train_dataset_initial = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(dataset_path, \"train\"),\n",
        "        image_size=(224, 224),\n",
        "        label_mode=\"categorical\",\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        seed=123\n",
        "    )\n",
        "    val_dataset_initial = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(dataset_path, \"val\"),\n",
        "        image_size=(224, 224),\n",
        "        label_mode=\"categorical\",\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        seed=123\n",
        "    )\n",
        "    test_dataset_initial = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(dataset_path, \"test\"),\n",
        "        image_size=(224, 224),\n",
        "        label_mode=\"categorical\",\n",
        "        batch_size=64,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Get class names before caching and prefetching\n",
        "    class_names = train_dataset_initial.class_names\n",
        "\n",
        "    train_dataset = train_dataset_initial.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    val_dataset = val_dataset_initial.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    test_dataset = test_dataset_initial.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, class_names\n",
        "\n",
        "# Call the load_datasets function and assign the returned values\n",
        "train_dataset, val_dataset, test_dataset, class_names = load_datasets()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaYriCK07UBi",
        "outputId": "df141e04-fcdf-4871-e724-714c9f458b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 76515 files belonging to 4 classes.\n",
            "Found 21861 files belonging to 4 classes.\n",
            "Found 10933 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf # Import tensorflow to access dataset attributes\n",
        "\n",
        "# DenseNet121 modelini yükle (önceden eğitilmiş ImageNet ağırlıklarıyla)\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Ağın sonuna kendi sınıflandırıcımızı ekleyelim\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "# Determine the number of classes from the training dataset\n",
        "# train_dataset is defined in the previous cell\n",
        "# Access class_names from the variable returned by load_datasets\n",
        "num_classes = len(class_names)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)  # num_classes değişkenini sınıf sayına göre ayarla\n",
        "\n",
        "# Yeni modeli oluştur\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Base modelin katmanlarını dondur\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modeli eğit (örnek)\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHrnYoXp7VEs",
        "outputId": "b1bf8dcb-c695-44df-a46a-f6d77aea3345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 879/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 151ms/step - accuracy: 0.7057 - loss: 0.8413"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Eğitim ve doğrulama doğruluklarını çiz\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.title('Model Doğruluk')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "\n",
        "# Eğitim ve doğrulama kayıplarını çiz\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.title('Model Kayıp')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kayıp')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b1tFBRnkAXUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Test verisi üzerinde modeli değerlendir\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Doğruluğu: {test_accuracy:.4f}\")\n",
        "print(f\"Test Kaybı: {test_loss:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0w9I5e1SAioe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf # Make sure tensorflow is imported for tf.data.Dataset\n",
        "\n",
        "# Gerçek ve tahmin edilen sınıfları al\n",
        "# Use the test_dataset directly with model.predict\n",
        "Y_pred = model.predict(test_dataset)\n",
        "\n",
        "# Since the labels are one-hot encoded (categorical), convert them back to class indices\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# To get the true labels from a tf.data.Dataset, you need to iterate over it.\n",
        "# It's important to do this carefully to match the order of predictions.\n",
        "# Assuming shuffle=False was used for the test_dataset, the order should match the directory listing order.\n",
        "# However, the most robust way is to reconstruct the true labels based on the dataset structure.\n",
        "# A simpler approach for classification report and confusion matrix with tf.data.Dataset\n",
        "# is to get the ground truth labels when the dataset is loaded.\n",
        "# We already have class_names from the load_datasets function.\n",
        "# We can get the true labels by iterating through the test_dataset and extracting the labels.\n",
        "\n",
        "# Extract true labels from the test_dataset\n",
        "y_true = []\n",
        "for images, labels in test_dataset.unbatch():\n",
        "    # labels are one-hot encoded, so find the index of the true class\n",
        "    y_true.append(np.argmax(labels.numpy()))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "\n",
        "# Sınıf adları already obtained from load_datasets function\n",
        "# class_names is available from the previous cell.\n",
        "\n",
        "# Sınıflandırma raporu\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Karışıklık matrisi\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "# Use class_names for the tick labels\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.ylabel('Gerçek Etiket')\n",
        "plt.xlabel('Tahmin Edilen Etiket')\n",
        "plt.title('Karışıklık Matrisi')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JhKe6PB2AtBK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}